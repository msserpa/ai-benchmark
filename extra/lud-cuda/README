LUD3->LUD2
LUD1->LUD5->LUD4
So it is better to rename index as:
LUD1 -> LUD3
LUD2 -> LUD2
LUD3 -> LUD1
LUD4 -> LUD5
LUD5 -> LUD4

* LUD 1 (lud_kernel_1.cu)
 Blocked LUD Algorithm using shared memory, implemented in three kernels. Refers to the paper
 [Woo94] Steven Cameron Woo, Jaswinder Pal Singh, and John L. Hennessy. 1994. The 
         performance advantages of integrating block data transfer in cache-coherent 
         multiprocessors. In Proceedings of the sixth international conference on 
         Architectural support for programming languages and operating systems (ASPLOS-VI). 
         ACM, New York, NY, USA, 219-229. DOI=10.1145/195473.195547 
         http://doi.acm.org/10.1145/195473.195547


* LUD 2 (lud_kernel_2.cu) 
Perform LUD based on the same algorithm used in baseline and omp, with
several iterations of two kernels. Use texture memory rather than shared memory



* LUD 3 (lud_kernel_3.cu)
Perform LUD based on the same algorithm used in baseline and omp, with
several iterations of two kernels. Global memory only.


* LUD 4 (lud_kernel_4.cu)
Implementation Description
Blocked LUD Algorithm. Perform LUD in several iterations of two CUDA kernels. The first kernel
"ludcmp_peri_col" computer peri-column of the matrix, the second kernel
"ludcmp_internal" update all the internal elements of the matrix.

 Use texture memory in "ludcmp_peri_col" and shared memory in "ludcmp_internal"


* LUD 5 (lud_kernel_5.cu)
Implementation Description
Perform LUD in several iterations of two CUDA kernels. The firest kernel
"ludcmp_peri_col" computer peri-column of the matrix, the second kernel
"ludcmp_internal" update all the internal elements of the matrix.

 Use shared memory in ludcmp_internal, no texture memory.

